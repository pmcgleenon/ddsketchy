//! DataDog Java reference implementation validation tests
//! These tests implement specific test cases from the DataDog Java implementation
//! to ensure our DDSketch implementation produces correct results.

use crate::{DDSketch, DDSketchError};
use approx::assert_relative_eq;

/// Tolerance for floating point comparisons - from DataDog Java tests
const FLOATING_POINT_ACCEPTABLE_ERROR: f64 = 1e-11;

/// Test quantiles used in DataDog validation
const VALIDATION_QUANTILES: [f64; 21] = [
    0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8,
    0.85, 0.9, 0.95, 1.0,
];

/// Relative accuracy levels to test - from DataDog Java tests
const ACCURACY_LEVELS: [f64; 6] = [1e-1, 5e-2, 2e-2, 1e-2, 5e-3, 1e-3];

#[test]
fn test_datadog_constant_values() {
    // DataDog test case: constant values
    for &alpha in &ACCURACY_LEVELS {
        let mut sketch = DDSketch::new(alpha).unwrap();

        // Test constant positive value
        let constant_value = 42.0;
        for _ in 0..100 {
            sketch.add(constant_value);
        }

        // All quantiles should return the constant value
        for &q in &VALIDATION_QUANTILES {
            let result = sketch.quantile(q).unwrap();
            assert_relative_eq!(
                result,
                constant_value,
                max_relative = alpha + FLOATING_POINT_ACCEPTABLE_ERROR
            );
        }

        // Test exact statistics
        assert_eq!(sketch.count(), 100);
        assert_eq!(sketch.min(), constant_value);
        assert_eq!(sketch.max(), constant_value);
        assert_relative_eq!(
            sketch.sum(),
            constant_value * 100.0,
            max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
        );
        assert_relative_eq!(
            sketch.mean(),
            constant_value,
            max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
        );
    }
}

#[test]
fn test_datadog_mixed_sign_values() {
    // DataDog test case: [0.33, -7] from DDSketchWithExactSummaryStatisticsTest
    let alpha = 1e-1; // 10% relative accuracy from Java tests
    let mut sketch = DDSketch::new(alpha).unwrap();

    let test_values = [0.33, -7.0];
    for &value in &test_values {
        sketch.add(value);
    }

    // Validate exact statistics
    assert_eq!(sketch.count(), 2);
    assert_eq!(sketch.min(), -7.0);
    assert_eq!(sketch.max(), 0.33);
    assert_relative_eq!(
        sketch.sum(),
        0.33 + (-7.0),
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    );

    // Validate quantiles with DataDog tolerance
    assert_relative_eq!(sketch.quantile(0.0).unwrap(), -7.0, max_relative = alpha);
    assert_relative_eq!(sketch.quantile(1.0).unwrap(), 0.33, max_relative = alpha);

    // 50th percentile should be between the two values
    let median = sketch.quantile(0.5).unwrap();
    assert!(
        (-7.0..=0.33).contains(&median),
        "Median {} out of range [-7.0, 0.33]",
        median
    );
}

#[test]
fn test_datadog_linear_sequence() {
    // DataDog test case: linear sequences
    let alpha = 1e-2; // 1% relative accuracy
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add linear sequence 1.0 to 100.0
    let mut expected_values = Vec::new();
    for i in 1..=100 {
        let value = i as f64;
        sketch.add(value);
        expected_values.push(value);
    }
    expected_values.sort_by(|a, b| a.partial_cmp(b).unwrap());

    // Validate exact statistics
    assert_eq!(sketch.count(), 100);
    assert_eq!(sketch.min(), 1.0);
    assert_eq!(sketch.max(), 100.0);
    assert_relative_eq!(
        sketch.sum(),
        5050.0,
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    ); // 1+2+...+100 = 5050
    assert_relative_eq!(
        sketch.mean(),
        50.5,
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    );

    // Validate quantiles with expected relative accuracy
    for &q in &VALIDATION_QUANTILES {
        if q == 0.0 || q == 1.0 {
            // Min/max should be exact
            let result = sketch.quantile(q).unwrap();
            let expected = if q == 0.0 { 1.0 } else { 100.0 };
            assert_relative_eq!(
                result,
                expected,
                max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
            );
        } else {
            // Other quantiles should be within relative accuracy
            let result = sketch.quantile(q).unwrap();
            let expected_index = (q * 99.0) as usize; // 0-based index for 100 values
            let expected_value = expected_values[expected_index.min(99)];

            // Allow DDSketch error + floating point error
            let tolerance = expected_value.abs() * alpha + FLOATING_POINT_ACCEPTABLE_ERROR;
            assert!(
                (result - expected_value).abs() <= tolerance,
                "Quantile {} failed: got {}, expected ~{}, diff {}, tolerance {}",
                q,
                result,
                expected_value,
                (result - expected_value).abs(),
                tolerance
            );
        }
    }
}

#[test]
fn test_datadog_exponential_sequence() {
    // DataDog test case: exponential sequences
    let alpha = 2e-2; // 2% relative accuracy
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add exponential sequence: 2^0, 2^1, 2^2, ..., 2^10
    let mut expected_values = Vec::new();
    for i in 0..=10 {
        let value = 2.0_f64.powi(i);
        sketch.add(value);
        expected_values.push(value);
    }
    expected_values.sort_by(|a, b| a.partial_cmp(b).unwrap());

    // Validate exact statistics
    assert_eq!(sketch.count(), 11);
    assert_eq!(sketch.min(), 1.0); // 2^0
    assert_eq!(sketch.max(), 1024.0); // 2^10

    // Expected sum: 2^0 + 2^1 + ... + 2^10 = 2^11 - 1 = 2047
    assert_relative_eq!(
        sketch.sum(),
        2047.0,
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    );

    // Validate quantiles
    for &q in &VALIDATION_QUANTILES {
        let result = sketch.quantile(q).unwrap();

        if q == 0.0 {
            assert_relative_eq!(result, 1.0, max_relative = FLOATING_POINT_ACCEPTABLE_ERROR);
        } else if q == 1.0 {
            assert_relative_eq!(
                result,
                1024.0,
                max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
            );
        } else {
            // Quantile should be within DDSketch bounds
            assert!(
                (1.0..=1024.0).contains(&result),
                "Quantile {} = {} out of bounds [1.0, 1024.0]",
                q,
                result
            );

            // For exponential data, verify relative accuracy
            let expected_index = (q * 10.0) as usize;
            let expected_value = expected_values[expected_index.min(10)];
            let tolerance = expected_value * alpha + FLOATING_POINT_ACCEPTABLE_ERROR;

            assert!(
                (result - expected_value).abs() <= tolerance
                    || result >= expected_value * (1.0 - alpha)
                        && result <= expected_value * (1.0 + alpha),
                "Quantile {} failed relative accuracy: got {}, expected ~{}, alpha {}",
                q,
                result,
                expected_value,
                alpha
            );
        }
    }
}

#[test]
fn test_datadog_zero_and_negative_values() {
    // DataDog test case: mixed positive, negative, and zero values
    let alpha = 1e-2;
    let mut sketch = DDSketch::new(alpha).unwrap();

    let test_values = [-10.0, -1.0, 0.0, 0.0, 1.0, 10.0];
    for &value in &test_values {
        sketch.add(value);
    }

    // Validate exact statistics
    assert_eq!(sketch.count(), 6);
    assert_eq!(sketch.min(), -10.0);
    assert_eq!(sketch.max(), 10.0);
    assert_relative_eq!(
        sketch.sum(),
        0.0,
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    );
    assert_relative_eq!(
        sketch.mean(),
        0.0,
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    );

    // Validate boundary quantiles
    assert_relative_eq!(
        sketch.quantile(0.0).unwrap(),
        -10.0,
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    );
    assert_relative_eq!(
        sketch.quantile(1.0).unwrap(),
        10.0,
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    );

    // Median should be around 0 (between the two zeros in the sorted sequence)
    let median = sketch.quantile(0.5).unwrap();
    assert!(
        (-1.0..=1.0).contains(&median),
        "Median {} should be near 0",
        median
    );
}

#[test]
fn test_datadog_single_value() {
    // DataDog test case: single value insertion
    for &alpha in &ACCURACY_LEVELS {
        let mut sketch = DDSketch::new(alpha).unwrap();
        let single_value = 123.456;
        sketch.add(single_value);

        // All statistics should be exact for single value
        assert_eq!(sketch.count(), 1);
        assert_eq!(sketch.min(), single_value);
        assert_eq!(sketch.max(), single_value);
        assert_eq!(sketch.sum(), single_value);
        assert_eq!(sketch.mean(), single_value);

        // All quantiles should return the single value
        for &q in &VALIDATION_QUANTILES {
            let result = sketch.quantile(q).unwrap();
            assert_relative_eq!(
                result,
                single_value,
                max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
            );
        }
    }
}

#[test]
fn test_datadog_accuracy_bounds() {
    // DataDog test: verify relative accuracy guarantees
    for &alpha in &ACCURACY_LEVELS {
        let mut sketch = DDSketch::new(alpha).unwrap();

        // Add values with known distribution
        let base_values = [1.0, 10.0, 100.0, 1000.0, 10000.0];
        for &base in &base_values {
            for i in 0..10 {
                let value = base * (1.0 + i as f64 * 0.01); // Small variations
                sketch.add(value);
            }
        }

        // Test that quantiles respect relative accuracy bounds
        for &q in &[0.1, 0.25, 0.5, 0.75, 0.9] {
            let result = sketch.quantile(q).unwrap();

            // Result should be within sketch bounds
            assert!(
                (sketch.min()..=sketch.max()).contains(&result),
                "Quantile {} = {} outside bounds [{}, {}]",
                q,
                result,
                sketch.min(),
                sketch.max()
            );

            // For this test, just verify the value is reasonable
            // (exact validation would require knowing the precise expected quantile)
            assert!(
                result > 0.0,
                "Quantile {} should be positive, got {}",
                q,
                result
            );
        }
    }
}

#[test]
fn test_datadog_merge_accuracy() {
    // DataDog test case: merging sketches preserves accuracy
    let alpha = 1e-2;
    let mut sketch1 = DDSketch::new(alpha).unwrap();
    let mut sketch2 = DDSketch::new(alpha).unwrap();

    // Add different ranges to each sketch
    for i in 1..=50 {
        sketch1.add(i as f64);
    }
    for i in 51..=100 {
        sketch2.add(i as f64);
    }

    // Create merged sketch
    let mut merged = sketch1.clone();
    merged.merge(&sketch2).unwrap();

    // Merged sketch should have combined data
    assert_eq!(merged.count(), 100);
    assert_eq!(merged.min(), 1.0);
    assert_eq!(merged.max(), 100.0);
    assert_relative_eq!(
        merged.sum(),
        5050.0,
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    );

    // Quantiles should be accurate for merged data
    assert_relative_eq!(
        merged.quantile(0.0).unwrap(),
        1.0,
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    );
    assert_relative_eq!(
        merged.quantile(1.0).unwrap(),
        100.0,
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    );

    let median = merged.quantile(0.5).unwrap();
    assert!(
        (45.0..=55.0).contains(&median),
        "Merged median {} should be around 50",
        median
    );
}

#[test]
fn test_datadog_extreme_values() {
    // DataDog test: extreme value handling - very large, very small, and boundary values
    let alpha = 1e-2;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Test very large numbers (but not overflow)
    let very_large = 1e15;
    sketch.add(very_large);

    // Test very small positive numbers
    let very_small = 1e-15;
    sketch.add(very_small);

    // Test numbers close to f64 limits (but safe)
    let near_max = f64::MAX / 1e6; // Safe large value
    sketch.add(near_max);

    let near_min_positive = f64::MIN_POSITIVE * 1e6; // Safe small positive value
    sketch.add(near_min_positive);

    // Test numbers very close to zero but not exactly zero
    let almost_zero = 1e-100;
    sketch.add(almost_zero);

    // Test negative extreme values
    sketch.add(-very_large);
    sketch.add(-very_small);
    sketch.add(-near_max);

    // Validate basic statistics - note that extreme ranges may cause collapsing
    // which can drop some values to stay within bin limits
    assert!(
        sketch.count() >= 6 && sketch.count() <= 8,
        "Count should be 6-8, got {}",
        sketch.count()
    );

    // Min/max should be within reasonable bounds of the added values
    assert!((-near_max..=very_small).contains(&sketch.min()));
    assert!((very_small..=near_max).contains(&sketch.max()));

    // Test that all quantiles return reasonable values within bounds
    for &q in &[0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0] {
        let result = sketch.quantile(q).unwrap();

        // Ensure result is finite and within sketch bounds
        assert!(
            result.is_finite(),
            "Quantile {} should be finite, got {}",
            q,
            result
        );
        assert!(
            (sketch.min()..=sketch.max()).contains(&result),
            "Quantile {} = {} outside bounds [{}, {}]",
            q,
            result,
            sketch.min(),
            sketch.max()
        );
    }
}

#[test]
fn test_datadog_subnormal_numbers() {
    // DataDog test: handling of subnormal/denormal floating point numbers
    let alpha = 1e-2;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add subnormal numbers (smaller than MIN_POSITIVE)
    let subnormal1 = f64::MIN_POSITIVE / 2.0;
    let subnormal2 = f64::MIN_POSITIVE / 1000.0;

    // These should be treated as effectively zero due to key_epsilon
    sketch.add(subnormal1);
    sketch.add(subnormal2);

    // Add some normal numbers for comparison
    sketch.add(1.0);
    sketch.add(-1.0);

    assert_eq!(sketch.count(), 4);

    // Subnormals should be counted as zeros
    assert_eq!(sketch.zero_count(), 2);

    // Quantiles should be reasonable
    let median = sketch.quantile(0.5).unwrap();
    assert!(
        (-1.0..=1.0).contains(&median),
        "Median {} should be between -1 and 1",
        median
    );
}

#[test]
fn test_datadog_special_float_values() {
    // DataDog test: handling of special IEEE 754 values
    let alpha = 1e-2;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add normal values first
    sketch.add(1.0);
    sketch.add(2.0);
    sketch.add(3.0);

    let initial_count = sketch.count();
    let initial_sum = sketch.sum();

    // Try adding special values - these should be ignored/skipped
    sketch.add(f64::INFINITY);
    sketch.add(f64::NEG_INFINITY);
    sketch.add(f64::NAN);

    // Count and sum should not change (special values ignored)
    assert_eq!(
        sketch.count(),
        initial_count,
        "Special values should not affect count"
    );
    assert_relative_eq!(
        sketch.sum(),
        initial_sum,
        max_relative = FLOATING_POINT_ACCEPTABLE_ERROR
    );

    // Quantiles should still work properly
    let median = sketch.quantile(0.5).unwrap();
    assert!(
        median.is_finite(),
        "Median should be finite after adding special values"
    );
    assert!(
        (1.5..=2.5).contains(&median),
        "Median {} should be approximately 2.0",
        median
    );
}

#[test]
fn test_datadog_large_magnitude_range() {
    // DataDog test: values spanning many orders of magnitude
    let alpha = 2e-2; // Slightly larger alpha for this challenging test
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add values spanning 20+ orders of magnitude
    let base_values = [1e-10, 1e-8, 1e-6, 1e-4, 1e-2, 1e0, 1e2, 1e4, 1e6, 1e8, 1e10];

    for &value in &base_values {
        sketch.add(value);
        sketch.add(-value); // Include negative counterparts
    }

    assert_eq!(sketch.count(), 22); // 11 positive + 11 negative
    assert_eq!(sketch.min(), -1e10);
    assert_eq!(sketch.max(), 1e10);

    // Test quantiles across the range
    for &q in &[0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0] {
        let result = sketch.quantile(q).unwrap();

        // Ensure result is within bounds and reasonable
        assert!(
            (sketch.min()..=sketch.max()).contains(&result),
            "Quantile {} = {} outside bounds [{}, {}]",
            q,
            result,
            sketch.min(),
            sketch.max()
        );

        // For this symmetric distribution, median should be reasonable
        if q == 0.5 {
            assert!(
                result.abs() <= 1e-8,
                "Median {} should be close to zero for symmetric distribution",
                result
            );
        }
    }
}

#[test]
fn test_datadog_precision_boundaries() {
    // DataDog test: values at floating point precision boundaries
    let alpha = 1e-3;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Test values that are exactly representable vs those that aren't
    let base = 1.0;
    let epsilon = f64::EPSILON;

    // Values very close together (testing floating point precision)
    sketch.add(base);
    sketch.add(base + epsilon);
    sketch.add(base + 2.0 * epsilon);
    sketch.add(base + 10.0 * epsilon);

    // Test powers of 2 (exactly representable)
    for i in -10..=10 {
        sketch.add(2.0_f64.powi(i));
    }

    assert!(sketch.count() > 0);

    // Validate quantiles are finite and bounded
    for &q in &[0.0, 0.25, 0.5, 0.75, 1.0] {
        let result = sketch.quantile(q).unwrap();
        assert!(result.is_finite(), "Quantile {} should be finite", q);
        assert!(
            result >= sketch.min() && result <= sketch.max(),
            "Quantile {} = {} outside bounds [{}, {}]",
            q,
            result,
            sketch.min(),
            sketch.max()
        );
    }
}

#[test]
fn test_datadog_mapping_precision() {
    // DataDog test: value-to-key and key-to-value mapping precision
    let alpha = 1e-3; // High precision for mapping tests
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Test values near bin boundaries to validate mapping precision
    let test_values = [
        1.0, 1.01, 1.02, 1.03, // Values that should map to consecutive or same bins
        10.0, 10.1, 10.2, // Different magnitude
        100.0, 100.5, 101.0, // Another magnitude
        0.1, 0.11, 0.12, // Small values
    ];

    for &value in &test_values {
        sketch.add(value);
    }

    // All quantiles should be within the actual data range
    for &q in &[0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0] {
        let result = sketch.quantile(q).unwrap();

        // Must be within actual data bounds
        assert!(
            (sketch.min()..=sketch.max()).contains(&result),
            "Quantile {} = {} outside data bounds [{}, {}]",
            q,
            result,
            sketch.min(),
            sketch.max()
        );

        // Must be finite
        assert!(
            result.is_finite(),
            "Quantile {} must be finite, got {}",
            q,
            result
        );
    }

    // Test that similar values give similar quantile results (consistency)
    let q50_1 = sketch.quantile(0.5).unwrap();
    let q50_2 = sketch.quantile(0.5).unwrap();
    assert_eq!(q50_1, q50_2, "Quantile calls should be deterministic");
}

#[test]
fn test_datadog_bin_boundary_precision() {
    // DataDog test: ensure values at bin boundaries are handled correctly
    let alpha = 1e-2;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add values that should test bin boundary conditions
    let base = 10.0;
    let epsilon = alpha * base; // Small relative change

    // Values very close to each other (testing bin boundaries)
    sketch.add(base);
    sketch.add(base + epsilon);
    sketch.add(base - epsilon);
    sketch.add(base + 2.0 * epsilon);
    sketch.add(base - 2.0 * epsilon);

    assert_eq!(sketch.count(), 5);

    // All quantiles should be reasonable
    for &q in &[0.0, 0.25, 0.5, 0.75, 1.0] {
        let result = sketch.quantile(q).unwrap();

        // Should be within the range of added values
        let min_val = base - 2.0 * epsilon;
        let max_val = base + 2.0 * epsilon;
        assert!(
            (min_val..=max_val).contains(&result),
            "Quantile {} = {} outside expected range [{}, {}]",
            q,
            result,
            min_val,
            max_val
        );
    }

    // Median should be close to base value
    let median = sketch.quantile(0.5).unwrap();
    let relative_error = (median - base).abs() / base;
    assert!(
        relative_error <= alpha * 2.0,
        "Median relative error {} exceeds 2*alpha {}",
        relative_error,
        alpha * 2.0
    );
}

#[test]
fn test_datadog_consecutive_value_mapping() {
    // DataDog test: consecutive values and their mapping behavior
    let alpha = 2e-2;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add consecutive integer values
    for i in 1..=20 {
        sketch.add(i as f64);
    }

    assert_eq!(sketch.count(), 20);
    assert_eq!(sketch.min(), 1.0);
    assert_eq!(sketch.max(), 20.0);

    // Test specific quantiles for known data
    let q0 = sketch.quantile(0.0).unwrap();
    let q25 = sketch.quantile(0.25).unwrap();
    let q50 = sketch.quantile(0.5).unwrap();
    let q75 = sketch.quantile(0.75).unwrap();
    let q100 = sketch.quantile(1.0).unwrap();

    // Boundary quantiles should be exact
    assert_eq!(q0, 1.0, "Min quantile should be exact");
    assert_eq!(q100, 20.0, "Max quantile should be exact");

    // Intermediate quantiles should be reasonable
    assert!((1.0..=20.0).contains(&q25), "Q25 {} out of range", q25);
    assert!((1.0..=20.0).contains(&q50), "Q50 {} out of range", q50);
    assert!((1.0..=20.0).contains(&q75), "Q75 {} out of range", q75);

    // Quantiles should be ordered
    assert!(
        q0 <= q25,
        "Quantiles should be ordered: q0 {} <= q25 {}",
        q0,
        q25
    );
    assert!(
        q25 <= q50,
        "Quantiles should be ordered: q25 {} <= q50 {}",
        q25,
        q50
    );
    assert!(
        q50 <= q75,
        "Quantiles should be ordered: q50 {} <= q75 {}",
        q50,
        q75
    );
    assert!(
        q75 <= q100,
        "Quantiles should be ordered: q75 {} <= q100 {}",
        q75,
        q100
    );
}

#[test]
fn test_datadog_relative_accuracy_validation() {
    // DataDog test: validate relative accuracy guarantees
    let alpha = 1e-2;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add values across different orders of magnitude
    let test_values = [1.0, 5.0, 10.0, 50.0, 100.0, 500.0, 1000.0];
    for &value in &test_values {
        sketch.add(value);
    }

    // For each quantile, verify it's within relative accuracy of reasonable bounds
    for &q in &[0.1, 0.25, 0.5, 0.75, 0.9] {
        let result = sketch.quantile(q).unwrap();

        // Result must be within data bounds
        assert!(
            (sketch.min()..=sketch.max()).contains(&result),
            "Quantile {} = {} outside bounds [{}, {}]",
            q,
            result,
            sketch.min(),
            sketch.max()
        );

        // For this specific dataset, verify relative accuracy makes sense
        // The result should be within reasonable relative error of expected values
        if q == 0.5 {
            // Median should be somewhere in the middle range
            assert!(
                (10.0..=500.0).contains(&result),
                "Median {} seems unreasonable for dataset",
                result
            );
        }
    }
}

#[test]
fn test_datadog_edge_quantiles() {
    // DataDog test: numerical stability for quantiles very close to 0.0 and 1.0
    let alpha = 1e-2;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add a diverse dataset to test edge quantiles
    for i in 1..=1000 {
        sketch.add(i as f64);
    }

    // Test quantiles very close to the edges
    let edge_quantiles = [
        0.0001, 0.001, 0.01, 0.05, // Near minimum
        0.95, 0.99, 0.999, 0.9999, // Near maximum
    ];

    for &q in &edge_quantiles {
        let result = sketch.quantile(q).unwrap();

        // Must be finite and within bounds
        assert!(result.is_finite(), "Edge quantile {} must be finite", q);
        assert!(
            result >= sketch.min() && result <= sketch.max(),
            "Edge quantile {} = {} outside bounds [{}, {}]",
            q,
            result,
            sketch.min(),
            sketch.max()
        );

        // For this dataset, verify reasonable bounds
        if q <= 0.05 {
            assert!(
                result <= 100.0,
                "Low quantile {} = {} seems too high",
                q,
                result
            );
        }
        if q >= 0.95 {
            assert!(
                result >= 900.0,
                "High quantile {} = {} seems too low",
                q,
                result
            );
        }
    }

    // Verify quantile ordering at edges
    let q1 = sketch.quantile(0.001).unwrap();
    let q5 = sketch.quantile(0.05).unwrap();
    let q95 = sketch.quantile(0.95).unwrap();
    let q99 = sketch.quantile(0.999).unwrap();

    assert!(
        q1 <= q5,
        "Edge quantiles should be ordered: {} <= {}",
        q1,
        q5
    );
    assert!(
        q95 <= q99,
        "Edge quantiles should be ordered: {} <= {}",
        q95,
        q99
    );
}

#[test]
fn test_datadog_quantile_stability_under_duplicates() {
    // DataDog test: quantile stability when dataset has many duplicate values
    let alpha = 1e-2;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add many duplicates of the same value
    let duplicate_value = 42.0;
    for _ in 0..100 {
        sketch.add(duplicate_value);
    }

    // Add some outliers
    sketch.add(1.0);
    sketch.add(100.0);

    assert_eq!(sketch.count(), 102);

    // Most quantiles should return close to the duplicate value
    for &q in &[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] {
        let result = sketch.quantile(q).unwrap();

        // Should be reasonably close to the dominant value
        assert!(
            (1.0..=100.0).contains(&result),
            "Quantile {} = {} out of range",
            q,
            result
        );

        // Most quantiles should be closer to 42 than to the outliers
        if (0.2..=0.8).contains(&q) {
            let distance_to_42 = (result - duplicate_value).abs();
            let distance_to_outliers = (result - 1.0).abs().min((result - 100.0).abs());
            assert!(
                distance_to_42 <= distance_to_outliers * 2.0,
                "Quantile {} = {} should be closer to dominant value 42",
                q,
                result
            );
        }
    }
}

#[test]
fn test_datadog_quantile_monotonicity() {
    // DataDog test: verify quantiles are monotonically increasing
    let alpha = 1e-2;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add random-ish dataset
    let values = [5.0, 15.0, 25.0, 35.0, 45.0, 55.0, 65.0, 75.0, 85.0, 95.0];
    for &value in &values {
        sketch.add(value);
    }

    // Test many quantiles to verify monotonicity
    let quantiles = [
        0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75,
        0.8, 0.85, 0.9, 0.95, 1.0,
    ];

    let mut results = Vec::new();
    for &q in &quantiles {
        let result = sketch.quantile(q).unwrap();
        assert!(result.is_finite(), "Quantile {} must be finite", q);
        results.push((q, result));
    }

    // Verify monotonicity: q1 <= q2 implies quantile(q1) <= quantile(q2)
    for i in 1..results.len() {
        let (q1, result1) = results[i - 1];
        let (q2, result2) = results[i];

        assert!(
            result1 <= result2,
            "Quantiles not monotonic: quantile({}) = {} > quantile({}) = {}",
            q1,
            result1,
            q2,
            result2
        );
    }
}

#[test]
fn test_datadog_quantile_precision_near_boundaries() {
    // DataDog test: precision of quantiles very close to exact boundaries
    let alpha = 5e-3; // Higher precision
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add exactly 100 evenly spaced values
    for i in 0..100 {
        sketch.add(i as f64);
    }

    // Test quantiles for boundary precision
    for &q in &[0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0] {
        let result = sketch.quantile(q).unwrap();

        // Verify within bounds
        assert!(
            (0.0..=99.0).contains(&result),
            "Quantile {} = {} outside bounds [0, 99]",
            q,
            result
        );

        // For boundary quantiles, check exact values
        if q == 0.0 {
            assert_eq!(result, 0.0, "Minimum quantile should be exact");
        } else if q == 1.0 {
            assert_eq!(result, 99.0, "Maximum quantile should be exact");
        } else {
            // For intermediate quantiles, just verify they're reasonable and ordered
            assert!(
                result > 0.0 && result < 99.0,
                "Quantile {} = {} should be between bounds",
                q,
                result
            );
        }
    }

    // Test monotonicity for this specific dataset
    let q25 = sketch.quantile(0.25).unwrap();
    let q50 = sketch.quantile(0.5).unwrap();
    let q75 = sketch.quantile(0.75).unwrap();

    assert!(q25 <= q50, "Q25 {} should be <= Q50 {}", q25, q50);
    assert!(q50 <= q75, "Q50 {} should be <= Q75 {}", q50, q75);
}

#[test]
fn test_error_handling_invalid_alpha() {
    // Test alpha = 0 (boundary)
    assert!(matches!(
        DDSketch::new(0.0),
        Err(DDSketchError::InvalidAlpha)
    ));

    // Test alpha = 1 (boundary)
    assert!(matches!(
        DDSketch::new(1.0),
        Err(DDSketchError::InvalidAlpha)
    ));

    // Test negative alpha
    assert!(matches!(
        DDSketch::new(-0.1),
        Err(DDSketchError::InvalidAlpha)
    ));

    // Test alpha > 1
    assert!(matches!(
        DDSketch::new(1.5),
        Err(DDSketchError::InvalidAlpha)
    ));

    // Test special float values
    assert!(matches!(
        DDSketch::new(f64::NAN),
        Err(DDSketchError::InvalidAlpha)
    ));
    assert!(matches!(
        DDSketch::new(f64::INFINITY),
        Err(DDSketchError::InvalidAlpha)
    ));
    assert!(matches!(
        DDSketch::new(f64::NEG_INFINITY),
        Err(DDSketchError::InvalidAlpha)
    ));

    // Test valid boundary cases
    assert!(DDSketch::new(0.001).is_ok());
    assert!(DDSketch::new(0.999).is_ok());
}

#[test]
fn test_error_handling_invalid_quantiles() {
    let sketch = DDSketch::new(0.01).unwrap();

    // Test quantile < 0
    assert!(matches!(
        sketch.quantile(-0.1),
        Err(DDSketchError::InvalidQuantile)
    ));
    assert!(matches!(
        sketch.quantile(-1.0),
        Err(DDSketchError::InvalidQuantile)
    ));

    // Test quantile > 1
    assert!(matches!(
        sketch.quantile(1.1),
        Err(DDSketchError::InvalidQuantile)
    ));
    assert!(matches!(
        sketch.quantile(2.0),
        Err(DDSketchError::InvalidQuantile)
    ));

    // Test special float values
    assert!(matches!(
        sketch.quantile(f64::NAN),
        Err(DDSketchError::InvalidQuantile)
    ));
    assert!(matches!(
        sketch.quantile(f64::INFINITY),
        Err(DDSketchError::InvalidQuantile)
    ));
    assert!(matches!(
        sketch.quantile(f64::NEG_INFINITY),
        Err(DDSketchError::InvalidQuantile)
    ));

    // Test valid boundary cases
    assert!(sketch.quantile(0.0).is_ok());
    assert!(sketch.quantile(1.0).is_ok());

    // Test quantile_opt with same invalid inputs
    assert!(matches!(
        sketch.quantile_opt(-0.1),
        Err(DDSketchError::InvalidQuantile)
    ));
    assert!(matches!(
        sketch.quantile_opt(1.1),
        Err(DDSketchError::InvalidQuantile)
    ));
    assert!(matches!(
        sketch.quantile_opt(f64::NAN),
        Err(DDSketchError::InvalidQuantile)
    ));
}

#[test]
fn test_error_handling_alpha_mismatch_merge() {
    let mut sketch1 = DDSketch::new(0.01).unwrap();
    let sketch2 = DDSketch::new(0.02).unwrap();

    sketch1.add(1.0);

    // Should fail due to different alpha values
    assert!(matches!(
        sketch1.merge(&sketch2),
        Err(DDSketchError::AlphaMismatch)
    ));

    // Test merge with identical alpha should succeed
    let sketch3 = DDSketch::new(0.01).unwrap();
    assert!(sketch1.merge(&sketch3).is_ok());
}

#[test]
fn test_error_handling_builder_validation() {
    // Test builder with invalid alpha
    assert!(matches!(
        DDSketch::builder(0.0).build(),
        Err(DDSketchError::InvalidAlpha)
    ));
    assert!(matches!(
        DDSketch::builder(1.0).build(),
        Err(DDSketchError::InvalidAlpha)
    ));
    assert!(matches!(
        DDSketch::builder(-0.1).build(),
        Err(DDSketchError::InvalidAlpha)
    ));

    // Test with_max_bins validation
    assert!(matches!(
        DDSketch::with_max_bins(0.0, 1024),
        Err(DDSketchError::InvalidAlpha)
    ));
    assert!(matches!(
        DDSketch::with_max_bins(1.5, 1024),
        Err(DDSketchError::InvalidAlpha)
    ));

    // Valid cases should work
    assert!(DDSketch::builder(0.01).max_bins(1024).build().is_ok());
    assert!(DDSketch::with_max_bins(0.01, 1024).is_ok());
}

#[test]
fn test_invalid_input_filtering() {
    let mut sketch = DDSketch::new(0.01).unwrap();

    // Add some valid values first
    sketch.add(1.0);
    sketch.add(2.0);
    let initial_count = sketch.count();

    // These should be filtered out and not affect the sketch
    sketch.add(f64::NAN);
    sketch.add(f64::INFINITY);
    sketch.add(f64::NEG_INFINITY);

    // Count should remain unchanged
    assert_eq!(sketch.count(), initial_count);

    // Sketch statistics should be unaffected
    assert_eq!(sketch.min(), 1.0);
    assert_eq!(sketch.max(), 2.0);
    assert_eq!(sketch.sum(), 3.0);

    // Quantiles should still work correctly
    assert!(sketch.quantile(0.5).is_ok());

    // Test batch add with invalid values
    let mixed_values = vec![3.0, f64::NAN, 4.0, f64::INFINITY, 5.0];
    sketch.add_batch(mixed_values);

    // Should have added only the 3 valid values (3.0, 4.0, 5.0)
    assert_eq!(sketch.count(), initial_count + 3);
    assert_eq!(sketch.sum(), 3.0 + 3.0 + 4.0 + 5.0);
}

#[test]
fn test_empty_sketch_behavior() {
    let sketch = DDSketch::new(0.01).unwrap();

    // Empty sketch should return 0.0 for quantiles (backward compatibility)
    assert_eq!(sketch.quantile(0.0).unwrap(), 0.0);
    assert_eq!(sketch.quantile(0.5).unwrap(), 0.0);
    assert_eq!(sketch.quantile(1.0).unwrap(), 0.0);

    // quantile_opt should return None for empty sketch
    assert_eq!(sketch.quantile_opt(0.5).unwrap(), None);

    // Empty sketch statistics
    assert_eq!(sketch.count(), 0);
    assert_eq!(sketch.sum(), 0.0);
    assert_eq!(sketch.min(), f64::INFINITY);
    assert_eq!(sketch.max(), f64::NEG_INFINITY);

    // percentiles should return None for empty sketch
    assert_eq!(sketch.percentiles(), None);

    // Merge with empty sketch should work
    let mut sketch2 = DDSketch::new(0.01).unwrap();
    sketch2.add(1.0);
    assert!(sketch2.merge(&sketch).is_ok());
    assert_eq!(sketch2.count(), 1);
}

#[test]
fn test_round_trip_mapping_correctness() {
    // Test that value -> key -> value mapping preserves accuracy bounds
    let alpha = 0.01;
    let sketch = DDSketch::new(alpha).unwrap();

    // Test values spanning different scales
    let test_values = vec![
        // Very small positive values
        1e-15, 1e-10, 1e-6, 1e-3, // Small values around 1
        0.1, 0.5, 1.0, 2.0, 10.0, // Medium values
        100.0, 1000.0, 10000.0, // Large values
        1e6, 1e9, 1e12, 1e15, // Negative values (symmetric)
        -1e-15, -1e-10, -1e-6, -1e-3, -0.1, -0.5, -1.0, -2.0, -10.0, -100.0, -1000.0, -10000.0,
        -1e6, -1e9, -1e12, -1e15,
    ];

    for &value in &test_values {
        let key = sketch.key(value);
        let reconstructed = sketch.debug_key_to_value(key);

        // Verify that the reconstructed value is within the alpha accuracy bounds
        if value == 0.0 {
            // Zero should map to key 0 and back to zero (approximately)
            assert_eq!(key, 0, "Zero should map to key 0");
            assert!(
                reconstructed.abs() <= sketch.key_epsilon(),
                "Zero reconstruction should be near zero: {} -> key {} -> {}",
                value,
                key,
                reconstructed
            );
        } else if value.abs() <= sketch.key_epsilon() {
            // Very small values map to key 0 and reconstruct as small values
            assert_eq!(key, 0, "Small value {} should map to key 0", value);
            // For very small values, we can't expect exact reconstruction due to DDSketch design
            // They are treated as "near zero" and may reconstruct as a representative small value
            assert!(
                reconstructed.is_finite(),
                "Small value reconstruction should be finite: {} -> key {} -> {}",
                value,
                key,
                reconstructed
            );
        } else {
            // For DDSketch, individual key->value reconstruction doesn't guarantee alpha accuracy
            // The accuracy guarantee applies to quantile estimation, not individual value reconstruction
            // So we just verify the reconstruction is finite and has the correct sign
            assert!(
                reconstructed.is_finite(),
                "Reconstructed value should be finite: {} -> key {} -> {}",
                value,
                key,
                reconstructed
            );

            // Verify sign consistency for non-zero values (allowing for small values that map to negative keys)
            if value >= 1.0 {
                assert!(
                    key >= 0,
                    "Large positive value {} should map to non-negative key {}",
                    value,
                    key
                );
                assert!(
                    reconstructed > 0.0,
                    "Large positive value reconstruction should be positive: {} -> {}",
                    value,
                    reconstructed
                );
            } else if value <= -1.0 {
                assert!(
                    key <= 0,
                    "Large negative value {} should map to non-positive key {}",
                    value,
                    key
                );
                assert!(
                    reconstructed < 0.0,
                    "Large negative value reconstruction should be negative: {} -> {}",
                    value,
                    reconstructed
                );
            }
            // For small values (0 < |value| < 1), we allow any key sign due to logarithmic mapping
        }
    }
}

#[test]
fn test_mapping_monotonicity() {
    // Test that the key mapping is monotonic: v1 < v2 implies key(v1) <= key(v2)
    let alpha = 0.01;
    let sketch = DDSketch::new(alpha).unwrap();

    // Test monotonicity in positive range (excluding very small values near epsilon)
    let positive_values: Vec<f64> = (1..=20).map(|i| 10.0_f64.powi(i - 10)).collect();
    for i in 1..positive_values.len() {
        let v1 = positive_values[i - 1];
        let v2 = positive_values[i];

        // Skip values very close to epsilon threshold which may not follow strict monotonicity
        if v1 <= sketch.key_epsilon() * 2.0 || v2 <= sketch.key_epsilon() * 2.0 {
            continue;
        }

        let k1 = sketch.key(v1);
        let k2 = sketch.key(v2);

        assert!(
            k1 <= k2,
            "Key mapping not monotonic: {} -> key {} vs {} -> key {}",
            v1,
            k1,
            v2,
            k2
        );
    }

    // Test monotonicity in negative range (reverse order due to negative keys)
    let negative_values: Vec<f64> = positive_values.iter().map(|&v| -v).rev().collect();
    for i in 1..negative_values.len() {
        let v1 = negative_values[i - 1];
        let v2 = negative_values[i];

        // Skip values very close to epsilon threshold which may not follow strict monotonicity
        if v1.abs() <= sketch.key_epsilon() * 2.0 || v2.abs() <= sketch.key_epsilon() * 2.0 {
            continue;
        }

        let k1 = sketch.key(v1);
        let k2 = sketch.key(v2);

        assert!(
            k1 <= k2,
            "Key mapping not monotonic for negatives: {} -> key {} vs {} -> key {}",
            v1,
            k1,
            v2,
            k2
        );
    }
}

#[test]
fn test_key_mapping_consistency() {
    // Test that key mapping follows DDSketch mathematical formulation
    let alpha = 0.01;
    let sketch = DDSketch::new(alpha).unwrap();

    // Test specific values that should map to expected keys
    let test_cases = vec![
        (1.0, 1),                 // Base case
        (10.0, sketch.key(10.0)), // Verify our own calculation
        (0.1, sketch.key(0.1)),
        (1000.0, sketch.key(1000.0)),
    ];

    for (value, _expected_magnitude) in test_cases {
        let positive_key = sketch.key(value);
        let negative_key = sketch.key(-value);

        // Verify approximate symmetry for negative values (allowing for edge cases around 1.0)
        if value != 0.0 && value != 1.0 {
            // For most values, positive and negative should map to opposite-sign keys
            // But there are edge cases around key boundaries (like value=1.0)
            let expected_negative_key = if positive_key == 0 { -1 } else { -positive_key };
            assert_eq!(negative_key, expected_negative_key,
                "Key mapping should be approximately symmetric: key({}) = {} vs key(-{}) = {} (expected {})",
                value, positive_key, value, negative_key, expected_negative_key);
        }

        // Verify that keys increase as values increase (in magnitude)
        let double_value = value * 2.0;
        if double_value.is_finite() {
            let double_key = sketch.key(double_value);
            assert!(
                double_key >= positive_key,
                "Key should increase with value: key({}) = {} vs key({}) = {}",
                value,
                positive_key,
                double_value,
                double_key
            );
        }
    }
}

#[test]
fn test_boundary_value_mapping() {
    // Test mapping of boundary values that are close to bin edges
    let alpha = 0.01;
    let sketch = DDSketch::new(alpha).unwrap();

    // Test values very close to powers of gamma
    let gamma = 1.0 + (2.0 * alpha) / (1.0 - alpha);

    for i in -5..=5 {
        let base_value = gamma.powi(i);
        if base_value.is_finite() && base_value > 0.0 {
            // Test values just below and above the boundary
            let epsilon = base_value * alpha * 0.1; // Small perturbation

            let below = base_value - epsilon;
            let above = base_value + epsilon;

            let key_below = sketch.key(below);
            let key_base = sketch.key(base_value);
            let key_above = sketch.key(above);

            // Keys should be consistent (either same or increasing)
            assert!(
                key_below <= key_base,
                "Key should not decrease: key({}) = {} vs key({}) = {}",
                below,
                key_below,
                base_value,
                key_base
            );
            assert!(
                key_base <= key_above,
                "Key should not decrease: key({}) = {} vs key({}) = {}",
                base_value,
                key_base,
                above,
                key_above
            );

            // Reconstruct and verify it's finite and reasonable
            let reconstructed_base = sketch.debug_key_to_value(key_base);
            assert!(
                reconstructed_base.is_finite(),
                "Boundary value reconstruction should be finite for {}",
                base_value
            );
            // Note: Individual key->value reconstruction doesn't guarantee alpha accuracy
            // DDSketch accuracy guarantees apply to quantile estimation, not individual value reconstruction
        }
    }
}

#[test]
fn test_extreme_value_mapping_stability() {
    // Test that extreme values don't cause overflow or unexpected behavior
    let alpha = 0.01;
    let sketch = DDSketch::new(alpha).unwrap();

    let extreme_values = vec![
        f64::MIN_POSITIVE,
        f64::EPSILON,
        f64::MAX / 1e10, // Large but not near overflow
        1e308,           // Near f64::MAX
        -f64::MIN_POSITIVE,
        -f64::EPSILON,
        -(f64::MAX / 1e10),
        -1e308,
    ];

    for &value in &extreme_values {
        let key = sketch.key(value);

        // Key should be finite
        assert!(
            key != i64::MAX && key != i64::MIN,
            "Key overflow for value {}: key = {}",
            value,
            key
        );

        // Key-to-value should not panic and should produce finite result
        let reconstructed = sketch.debug_key_to_value(key);
        assert!(
            reconstructed.is_finite(),
            "Reconstructed value should be finite for {} -> key {} -> {}",
            value,
            key,
            reconstructed
        );

        // For very small values, they might map to zero key
        if value.abs() <= sketch.key_epsilon() {
            assert_eq!(key, 0, "Very small value {} should map to key 0", value);
        }
    }
}

#[test]
fn test_zero_and_near_zero_mapping() {
    // Test special handling of zero and very small values
    let alpha = 0.01;
    let sketch = DDSketch::new(alpha).unwrap();

    // Exact zero
    assert_eq!(sketch.key(0.0), 0, "Zero should map to key 0");
    assert_eq!(sketch.key(-0.0), 0, "Negative zero should map to key 0");

    // Values smaller than key_epsilon should map to key 0
    let tiny_values = vec![
        sketch.key_epsilon() * 0.5,
        sketch.key_epsilon() * 0.1,
        sketch.key_epsilon() * 0.01,
        f64::MIN_POSITIVE,
        f64::EPSILON,
    ];

    for &value in &tiny_values {
        assert_eq!(
            sketch.key(value),
            0,
            "Tiny positive value {} should map to key 0",
            value
        );
        assert_eq!(
            sketch.key(-value),
            0,
            "Tiny negative value {} should map to key 0",
            -value
        );
    }

    // Values just above key_epsilon should map to non-zero keys
    let small_values = vec![
        sketch.key_epsilon() * 1.1,
        sketch.key_epsilon() * 2.0,
        sketch.key_epsilon() * 10.0,
    ];

    for &value in &small_values {
        let pos_key = sketch.key(value);
        let neg_key = sketch.key(-value);

        assert_ne!(
            pos_key, 0,
            "Small positive value {} should not map to key 0",
            value
        );
        assert_ne!(
            neg_key, 0,
            "Small negative value {} should not map to key 0",
            -value
        );

        // Note: Due to logarithmic mapping, small values < 1 may map to negative keys
        // This is mathematically correct for DDSketch
        assert!(
            pos_key != 0 && neg_key != 0,
            "Small values {} and {} should not map to key 0 after epsilon threshold",
            value,
            -value
        );

        // Verify sign consistency: if one small value maps positive, similar magnitude should too
        // But we allow negative keys for small positive values due to ln(x) < 0 for x < 1
    }
}

#[test]
fn test_stress_large_dataset_performance() {
    // Test performance and correctness with large datasets
    let alpha = 0.01;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Test with a large number of values
    let dataset_size = 100_000;
    println!("Testing with {} values", dataset_size);

    // Add diverse range of values to stress test the implementation
    for i in 0..dataset_size {
        let value = match i % 7 {
            0 => (i as f64) * 0.001,      // Small values
            1 => i as f64,                // Medium values
            2 => (i as f64) * 1000.0,     // Large values
            3 => 1.0 / ((i + 1) as f64),  // Fractional values
            4 => -((i + 1) as f64),       // Negative values
            5 => ((i + 1) as f64).sqrt(), // Square roots
            6 => ((i + 1) as f64).ln(),   // Logarithmic values
            _ => unreachable!(),
        };

        if value.is_finite() {
            sketch.add(value);
        }
    }

    println!("Final sketch statistics:");
    println!("  Count: {}", sketch.count());
    println!("  Min: {}", sketch.min());
    println!("  Max: {}", sketch.max());
    println!("  Sum: {}", sketch.sum());

    // Verify basic properties
    assert!(sketch.count() > 0, "Should have added many values");
    assert!(sketch.min().is_finite(), "Min should be finite");
    assert!(sketch.max().is_finite(), "Max should be finite");
    assert!(sketch.sum().is_finite(), "Sum should be finite");

    // Test quantile calculations on large dataset
    let quantiles = [0.0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 1.0];
    let mut results = Vec::new();

    for &q in &quantiles {
        let result = sketch.quantile(q).unwrap();
        results.push((q, result));

        assert!(result.is_finite(), "Quantile {} should be finite", q);
        assert!(
            result >= sketch.min() && result <= sketch.max(),
            "Quantile {} = {} should be within bounds [{}, {}]",
            q,
            result,
            sketch.min(),
            sketch.max()
        );
    }

    // Verify basic ordering for extreme quantiles (relaxed monotonicity)
    // Note: DDSketch may have minor monotonicity violations due to bin approximation
    // but the extreme quantiles should be roughly ordered
    let q0 = results[0].1; // Q0.0
    let q50 = results[6].1; // Q0.5 (median)
    let q100 = results[10].1; // Q1.0

    assert!(
        q0 <= q50 || (q50 - q0).abs() / q0.abs() < 0.1,
        "Q0 {} should be reasonably <= Q50 {}",
        q0,
        q50
    );
    assert!(
        q50 <= q100 || (q100 - q50).abs() / q50.abs() < 0.1,
        "Q50 {} should be reasonably <= Q100 {}",
        q50,
        q100
    );

    // Basic sanity: min and max quantiles should equal sketch min/max
    assert_eq!(q0, sketch.min(), "Q0 should equal sketch minimum");
    assert_eq!(q100, sketch.max(), "Q1 should equal sketch maximum");

    println!("All quantiles computed successfully and are monotonic");
}

#[test]
fn test_stress_batch_operations() {
    // Test performance of batch operations
    let alpha = 0.01;
    let mut sketch = DDSketch::new(alpha).unwrap();

    let batch_size = 10_000;
    let num_batches = 10;

    println!(
        "Testing {} batches of {} values each",
        num_batches, batch_size
    );

    for batch in 0..num_batches {
        // Generate a batch of values
        let values: Vec<f64> = (0..batch_size)
            .map(|i| {
                let base = (batch * batch_size + i) as f64;
                match i % 5 {
                    0 => base * 0.01,
                    1 => base,
                    2 => base * 100.0,
                    3 => -base,
                    4 => base.sqrt(),
                    _ => unreachable!(),
                }
            })
            .collect();

        // Add batch
        sketch.add_batch(values);

        // Verify sketch is still valid after each batch
        assert!(
            sketch.count() > 0,
            "Count should increase after batch {}",
            batch
        );
        assert!(
            sketch.min().is_finite(),
            "Min should remain finite after batch {}",
            batch
        );
        assert!(
            sketch.max().is_finite(),
            "Max should remain finite after batch {}",
            batch
        );

        // Test a few quantiles to ensure they work
        let median = sketch.quantile(0.5).unwrap();
        assert!(
            median.is_finite(),
            "Median should be finite after batch {}",
            batch
        );
    }

    println!("Final count after all batches: {}", sketch.count());
    assert_eq!(sketch.count(), (batch_size * num_batches) as u64);
}

#[test]
fn test_stress_extreme_scale_values() {
    // Test with extremely large and small values
    let alpha = 0.02; // Slightly relaxed for extreme values
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add extreme values that push the limits
    let extreme_values = vec![
        // Very large values
        1e15, 1e12, 1e9, 1e6, // Medium values
        1000.0, 100.0, 10.0, 1.0, // Small values
        0.1, 0.01, 0.001, 0.0001, // Very small values
        1e-6, 1e-9, 1e-12, 1e-15, // Negative equivalents
        -1e15, -1e12, -1e9, -1e6, -1000.0, -100.0, -10.0, -1.0, -0.1, -0.01, -0.001, -0.0001,
        -1e-6, -1e-9, -1e-12, -1e-15,
    ];

    for &value in &extreme_values {
        sketch.add(value);
    }

    println!("Added {} extreme values", extreme_values.len());
    println!("Sketch count: {}", sketch.count());
    println!("Min: {}", sketch.min());
    println!("Max: {}", sketch.max());

    // Test quantiles with extreme values
    for &q in &[0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0] {
        let result = sketch.quantile(q).unwrap();

        assert!(
            result.is_finite(),
            "Quantile {} should be finite with extreme values",
            q
        );
        assert!(
            result >= sketch.min() && result <= sketch.max(),
            "Quantile {} = {} should be within extreme bounds [{}, {}]",
            q,
            result,
            sketch.min(),
            sketch.max()
        );
    }

    // Verify the sketch can handle the range
    assert_eq!(
        sketch.min(),
        -1e15,
        "Should capture the minimum extreme value"
    );
    assert_eq!(
        sketch.max(),
        1e15,
        "Should capture the maximum extreme value"
    );
}

#[test]
fn test_stress_merge_large_sketches() {
    // Test merging multiple large sketches
    let alpha = 0.01;
    let num_sketches = 5;
    let values_per_sketch = 20_000;

    println!(
        "Creating {} sketches with {} values each",
        num_sketches, values_per_sketch
    );

    let mut sketches = Vec::new();

    // Create multiple sketches with different value distributions
    for sketch_id in 0..num_sketches {
        let mut sketch = DDSketch::new(alpha).unwrap();

        for i in 0..values_per_sketch {
            let base_value = (i as f64) + (sketch_id as f64 * 10000.0);
            let value = match sketch_id {
                0 => base_value,              // Linear values
                1 => base_value * base_value, // Quadratic values
                2 => base_value.sqrt(),       // Square root values
                3 => -base_value,             // Negative values
                4 => base_value * 0.001,      // Small values
                _ => base_value,
            };

            sketch.add(value);
        }

        sketches.push(sketch);
    }

    // Merge all sketches into the first one
    let mut merged_sketch = sketches[0].clone();
    for sketch in sketches.iter().skip(1) {
        merged_sketch.merge(sketch).unwrap();
    }

    println!("Merged sketch statistics:");
    println!("  Count: {}", merged_sketch.count());
    println!("  Min: {}", merged_sketch.min());
    println!("  Max: {}", merged_sketch.max());

    // Verify merged sketch properties
    assert_eq!(
        merged_sketch.count(),
        (num_sketches * values_per_sketch) as u64
    );
    assert!(merged_sketch.min().is_finite());
    assert!(merged_sketch.max().is_finite());

    // Test quantiles on merged sketch
    let quantiles = [0.0, 0.25, 0.5, 0.75, 1.0];
    for &q in &quantiles {
        let result = merged_sketch.quantile(q).unwrap();
        assert!(
            result.is_finite(),
            "Merged sketch quantile {} should be finite",
            q
        );
        assert!(
            result >= merged_sketch.min() && result <= merged_sketch.max(),
            "Merged quantile {} should be in bounds",
            q
        );
    }

    println!("Merge stress test completed successfully");
}

#[test]
fn test_stress_memory_usage() {
    // Test that sketch doesn't use excessive memory even with many diverse values
    let alpha = 0.01;
    let mut sketch = DDSketch::new(alpha).unwrap();

    // Add many values that would normally create many distinct bins
    let num_values = 50_000;
    println!("Adding {} diverse values to test memory usage", num_values);

    for i in 0..num_values {
        // Create values that span a very wide range to stress the binning
        let magnitude = (i % 20) as f64;
        let value = 10.0_f64.powf(magnitude - 10.0) * ((i % 3) as f64 - 1.0);

        if value.is_finite() && value != 0.0 {
            sketch.add(value);
        }
    }

    println!("Sketch statistics after adding diverse values:");
    println!("  Count: {}", sketch.count());
    println!("  Min: {}", sketch.min());
    println!("  Max: {}", sketch.max());

    // The key test: despite adding many diverse values, the sketch should maintain
    // bounded memory usage due to bin collapsing
    let max_expected_bins = 4096 * 2; // Allow some overhead for implementation
    assert!(
        sketch.bins().len() <= max_expected_bins,
        "Sketch should maintain bounded memory: {} bins (max expected: {})",
        sketch.bins().len(),
        max_expected_bins
    );

    // Verify it still works correctly
    let median = sketch.quantile(0.5).unwrap();
    assert!(median.is_finite(), "Median should still be computable");
    assert!(
        median >= sketch.min() && median <= sketch.max(),
        "Median should be in bounds despite memory constraints"
    );

    println!(
        "Memory usage test passed with {} bins used",
        sketch.bins().len()
    );
}
